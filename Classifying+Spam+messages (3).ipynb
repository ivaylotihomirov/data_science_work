{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                sms\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv('/Users/ivaylo.ivanov/Downloads/SMSSpamCollection', sep='\\t', header=None, names=['Label','sms'])\n",
    "print(file.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(file['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = file.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = file_1.iloc[:4458]\n",
    "test = file_1.iloc[4458:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>905</td>\n",
       "      <td>ham</td>\n",
       "      <td>We're all getting worried over here, derek and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>5192</td>\n",
       "      <td>ham</td>\n",
       "      <td>Oh oh... Den muz change plan liao... Go back h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>3980</td>\n",
       "      <td>ham</td>\n",
       "      <td>CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>235</td>\n",
       "      <td>spam</td>\n",
       "      <td>Text &amp; meet someone sexy today. U can find a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>5157</td>\n",
       "      <td>ham</td>\n",
       "      <td>K k:) sms chat with me.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index Label                                                sms\n",
       "0      2131   ham          Later i guess. I needa do mcat study too.\n",
       "1      3418   ham             But i haf enuff space got like 4 mb...\n",
       "2      3424  spam  Had your mobile 10 mths? Update to latest Oran...\n",
       "3      1538   ham  All sounds good. Fingers . Makes it difficult ...\n",
       "4      5393   ham  All done, all handed in. Don't know if mega sh...\n",
       "...     ...   ...                                                ...\n",
       "1109    905   ham  We're all getting worried over here, derek and...\n",
       "1110   5192   ham  Oh oh... Den muz change plan liao... Go back h...\n",
       "1111   3980   ham  CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
       "1112    235  spam  Text & meet someone sexy today. U can find a d...\n",
       "1113   5157   ham                            K k:) sms chat with me.\n",
       "\n",
       "[1114 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.reset_index()\n",
    "test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       4458\n",
       "unique                      4172\n",
       "top       Sorry, I'll call later\n",
       "freq                          21\n",
       "Name: sms, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['sms'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-c20e226127fd>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training['sms1'] = training['sms'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "training['sms1'] = training['sms'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       4458\n",
       "unique                      4172\n",
       "top       Sorry, I'll call later\n",
       "freq                          21\n",
       "Name: sms1, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['sms1'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use training set only - leave test set aside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                sms  \\\n",
      "1078   ham                       Yep, by the pretty sculpture   \n",
      "4028   ham      Yes, princess. Are you going to make me moan?   \n",
      "958    ham                         Welp apparently he retired   \n",
      "4642   ham                                            Havent.   \n",
      "4674   ham  I forgot 2 ask ü all smth.. There's a card on ...   \n",
      "\n",
      "                                                   sms1  \\\n",
      "1078                       Yep, by the pretty sculpture   \n",
      "4028      Yes, princess. Are you going to make me moan?   \n",
      "958                          Welp apparently he retired   \n",
      "4642                                            Havent.   \n",
      "4674  I forgot 2 ask ü all smth.. There's a card on ...   \n",
      "\n",
      "                                                   sms2  \\\n",
      "1078                       Yep  by the pretty sculpture   \n",
      "4028      Yes  princess  Are you going to make me moan    \n",
      "958                          Welp apparently he retired   \n",
      "4642                                            Havent    \n",
      "4674  I forgot 2 ask ü all smth   There s a card on ...   \n",
      "\n",
      "                                                   sms3  \n",
      "1078                       yep  by the pretty sculpture  \n",
      "4028      yes  princess  are you going to make me moan   \n",
      "958                          welp apparently he retired  \n",
      "4642                                            havent   \n",
      "4674  i forgot 2 ask ü all smth   there s a card on ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-e709e94dc605>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training['sms2'] = training['sms1'].str.replace('\\W',' ')\n",
      "<ipython-input-43-e709e94dc605>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training['sms3'] = training['sms2'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "training['sms2'] = training['sms1'].str.replace('\\W',' ')\n",
    "training['sms3'] = training['sms2'].str.lower()\n",
    "print(training.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                sms  \\\n",
      "1078   ham                 [Yep,, by, the, pretty, sculpture]   \n",
      "4028   ham  [Yes,, princess., Are, you, going, to, make, m...   \n",
      "958    ham                    [Welp, apparently, he, retired]   \n",
      "4642   ham                                          [Havent.]   \n",
      "4674   ham  [I, forgot, 2, ask, ü, all, smth.., There's, a...   \n",
      "\n",
      "                                                   sms1  \\\n",
      "1078                       Yep, by the pretty sculpture   \n",
      "4028      Yes, princess. Are you going to make me moan?   \n",
      "958                          Welp apparently he retired   \n",
      "4642                                            Havent.   \n",
      "4674  I forgot 2 ask ü all smth.. There's a card on ...   \n",
      "\n",
      "                                                   sms2  \\\n",
      "1078                       Yep  by the pretty sculpture   \n",
      "4028      Yes  princess  Are you going to make me moan    \n",
      "958                          Welp apparently he retired   \n",
      "4642                                            Havent    \n",
      "4674  I forgot 2 ask ü all smth   There s a card on ...   \n",
      "\n",
      "                                                   sms3  \n",
      "1078                  [yep, by, the, pretty, sculpture]  \n",
      "4028  [yes, princess, are, you, going, to, make, me,...  \n",
      "958                     [welp, apparently, he, retired]  \n",
      "4642                                           [havent]  \n",
      "4674  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-a0e471e20ee8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training['sms3'] = training['sms3'].str.split()\n"
     ]
    }
   ],
   "source": [
    "training['sms3'] = training['sms3'].str.split()\n",
    "print(training.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yep', 'by', 'the', 'pretty', 'sculpture']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "for i in training['sms3']:\n",
    "    for j in i:\n",
    "        vocabulary.append(j)\n",
    "print(vocabulary[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_1 = set(vocabulary)\n",
    "vocabulary_2 = list(vocabulary_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accenture', 'can', '81618', 'correctly', 'smoking']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['sms3']) for unique_word in vocabulary_2}\n",
    "\n",
    "for index, sms in enumerate(training['sms3']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accenture</th>\n",
       "      <th>can</th>\n",
       "      <th>81618</th>\n",
       "      <th>correctly</th>\n",
       "      <th>smoking</th>\n",
       "      <th>answers</th>\n",
       "      <th>lucky</th>\n",
       "      <th>signin</th>\n",
       "      <th>gifts</th>\n",
       "      <th>leadership</th>\n",
       "      <th>...</th>\n",
       "      <th>9153</th>\n",
       "      <th>checkmate</th>\n",
       "      <th>radiator</th>\n",
       "      <th>road</th>\n",
       "      <th>apo</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>takecare</th>\n",
       "      <th>tuition</th>\n",
       "      <th>kanagu</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accenture  can  81618  correctly  smoking  answers  lucky  signin  gifts  \\\n",
       "0          0    0      0          0        0        0      0       0      0   \n",
       "1          0    0      0          0        0        0      0       0      0   \n",
       "2          0    0      0          0        0        0      0       0      0   \n",
       "3          0    0      0          0        0        0      0       0      0   \n",
       "4          0    0      0          0        0        0      0       0      0   \n",
       "\n",
       "   leadership  ...  9153  checkmate  radiator  road  apo  yesterday  takecare  \\\n",
       "0           0  ...     0          0         0     0    0          0         0   \n",
       "1           0  ...     0          0         0     0    0          0         0   \n",
       "2           0  ...     0          0         0     0    0          0         0   \n",
       "3           0  ...     0          0         0     0    0          0         0   \n",
       "4           0  ...     0          0         0     0    0          0         0   \n",
       "\n",
       "   tuition  kanagu  days  \n",
       "0        0       0     0  \n",
       "1        0       0     0  \n",
       "2        0       0     0  \n",
       "3        0       0     0  \n",
       "4        0       0     0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.DataFrame(word_counts_per_sms)\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_new = pd.concat([training, words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                sms  \\\n",
      "0   ham  [Go, until, jurong, point,, crazy.., Available...   \n",
      "1   ham               [Ok, lar..., Joking, wif, u, oni...]   \n",
      "2   NaN                                                NaN   \n",
      "3   ham  [U, dun, say, so, early, hor..., U, c, already...   \n",
      "4   ham  [Nah, I, don't, think, he, goes, to, usf,, he,...   \n",
      "\n",
      "                                                sms1  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2                                                NaN   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                                sms2  \\\n",
      "0  Go until jurong point  crazy   Available only ...   \n",
      "1                      Ok lar    Joking wif u oni      \n",
      "2                                                NaN   \n",
      "3  U dun say so early hor    U c already then say      \n",
      "4  Nah I don t think he goes to usf  he lives aro...   \n",
      "\n",
      "                                                sms3  accenture  can  81618  \\\n",
      "0  [go, until, jurong, point, crazy, available, o...        0.0  0.0    0.0   \n",
      "1                     [ok, lar, joking, wif, u, oni]        0.0  0.0    0.0   \n",
      "2                                                NaN        0.0  0.0    0.0   \n",
      "3  [u, dun, say, so, early, hor, u, c, already, t...        0.0  0.0    0.0   \n",
      "4  [nah, i, don, t, think, he, goes, to, usf, he,...        0.0  0.0    0.0   \n",
      "\n",
      "   correctly  smoking  ...  9153  checkmate  radiator  road  apo  yesterday  \\\n",
      "0        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "1        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "2        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "3        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "4        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "\n",
      "   takecare  tuition  kanagu  days  \n",
      "0       0.0      0.0     0.0   0.0  \n",
      "1       0.0      0.0     0.0   0.0  \n",
      "2       0.0      0.0     0.0   0.0  \n",
      "3       0.0      0.0     0.0   0.0  \n",
      "4       0.0      0.0     0.0   0.0  \n",
      "\n",
      "[5 rows x 7788 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254\n",
      "0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "p_spam = training_new['Label'].value_counts(normalize=True)[1]\n",
    "p_ham = training_new['Label'].value_counts(normalize=True)[0]\n",
    "print(p_spam)\n",
    "print(p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "training_spam = training_new[training_new['Label']=='spam']\n",
    "training_ham = training_new[training_new['Label']=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5       36\n",
      "8       26\n",
      "9       29\n",
      "11      28\n",
      "12      30\n",
      "        ..\n",
      "5537    17\n",
      "5540    33\n",
      "5547    27\n",
      "5566    29\n",
      "5567    32\n",
      "Name: sms3, Length: 600, dtype: int64\n",
      "15190\n",
      "57237\n",
      "7783\n"
     ]
    }
   ],
   "source": [
    "words_spam = training_spam['sms3'].apply(len)\n",
    "n_spam = words_spam.sum()\n",
    "words_ham = training_ham['sms3'].apply(len)\n",
    "n_ham = words_ham.sum()\n",
    "n_vocabulary = len(vocabulary_2)\n",
    "\n",
    "print(words_spam)\n",
    "\n",
    "print(n_spam)\n",
    "print(n_ham)\n",
    "print(n_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                                sms  \\\n",
      "5   spam  [FreeMsg, Hey, there, darling, it's, been, 3, ...   \n",
      "8   spam  [WINNER!!, As, a, valued, network, customer, y...   \n",
      "9   spam  [Had, your, mobile, 11, months, or, more?, U, ...   \n",
      "11  spam  [SIX, chances, to, win, CASH!, From, 100, to, ...   \n",
      "12  spam  [URGENT!, You, have, won, a, 1, week, FREE, me...   \n",
      "\n",
      "                                                 sms1  \\\n",
      "5   FreeMsg Hey there darling it's been 3 week's n...   \n",
      "8   WINNER!! As a valued network customer you have...   \n",
      "9   Had your mobile 11 months or more? U R entitle...   \n",
      "11  SIX chances to win CASH! From 100 to 20,000 po...   \n",
      "12  URGENT! You have won a 1 week FREE membership ...   \n",
      "\n",
      "                                                 sms2  \\\n",
      "5   FreeMsg Hey there darling it s been 3 week s n...   \n",
      "8   WINNER   As a valued network customer you have...   \n",
      "9   Had your mobile 11 months or more  U R entitle...   \n",
      "11  SIX chances to win CASH  From 100 to 20 000 po...   \n",
      "12  URGENT  You have won a 1 week FREE membership ...   \n",
      "\n",
      "                                                 sms3  accenture  can  81618  \\\n",
      "5   [freemsg, hey, there, darling, it, s, been, 3,...        0.0  0.0    0.0   \n",
      "8   [winner, as, a, valued, network, customer, you...        0.0  0.0    0.0   \n",
      "9   [had, your, mobile, 11, months, or, more, u, r...        0.0  0.0    0.0   \n",
      "11  [six, chances, to, win, cash, from, 100, to, 2...        0.0  0.0    0.0   \n",
      "12  [urgent, you, have, won, a, 1, week, free, mem...        0.0  0.0    0.0   \n",
      "\n",
      "    correctly  smoking  ...  9153  checkmate  radiator  road  apo  yesterday  \\\n",
      "5         0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "8         0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "9         0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "11        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "12        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "\n",
      "    takecare  tuition  kanagu  days  \n",
      "5        0.0      0.0     0.0   0.0  \n",
      "8        0.0      0.0     0.0   0.0  \n",
      "9        0.0      0.0     0.0   0.0  \n",
      "11       0.0      0.0     0.0   0.0  \n",
      "12       0.0      0.0     0.0   0.0  \n",
      "\n",
      "[5 rows x 7788 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_spam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                                sms  \\\n",
      "0   ham  [Go, until, jurong, point,, crazy.., Available...   \n",
      "1   ham               [Ok, lar..., Joking, wif, u, oni...]   \n",
      "2   NaN                                                NaN   \n",
      "3   ham  [U, dun, say, so, early, hor..., U, c, already...   \n",
      "4   ham  [Nah, I, don't, think, he, goes, to, usf,, he,...   \n",
      "\n",
      "                                                sms1  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2                                                NaN   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                                sms2  \\\n",
      "0  Go until jurong point  crazy   Available only ...   \n",
      "1                      Ok lar    Joking wif u oni      \n",
      "2                                                NaN   \n",
      "3  U dun say so early hor    U c already then say      \n",
      "4  Nah I don t think he goes to usf  he lives aro...   \n",
      "\n",
      "                                                sms3  accenture  can  81618  \\\n",
      "0  [go, until, jurong, point, crazy, available, o...        0.0  0.0    0.0   \n",
      "1                     [ok, lar, joking, wif, u, oni]        0.0  0.0    0.0   \n",
      "2                                                NaN        0.0  0.0    0.0   \n",
      "3  [u, dun, say, so, early, hor, u, c, already, t...        0.0  0.0    0.0   \n",
      "4  [nah, i, don, t, think, he, goes, to, usf, he,...        0.0  0.0    0.0   \n",
      "\n",
      "   correctly  smoking  ...  9153  checkmate  radiator  road  apo  yesterday  \\\n",
      "0        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "1        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "2        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "3        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "4        0.0      0.0  ...   0.0        0.0       0.0   0.0  0.0        0.0   \n",
      "\n",
      "   takecare  tuition  kanagu  days  \n",
      "0       0.0      0.0     0.0   0.0  \n",
      "1       0.0      0.0     0.0   0.0  \n",
      "2       0.0      0.0     0.0   0.0  \n",
      "3       0.0      0.0     0.0   0.0  \n",
      "4       0.0      0.0     0.0   0.0  \n",
      "\n",
      "[5 rows x 7788 columns]\n"
     ]
    }
   ],
   "source": [
    "print(training_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dict = {word:0 for word in vocabulary_2}\n",
    "ham_dict = {word:0 for word in vocabulary_2} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocabulary_2[:4000]:\n",
    "    n_word_spam = training_spam[i].sum()\n",
    "    p_spam = (n_word_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_dict[i] = p_spam\n",
    "    \n",
    "    n_word_ham = training_ham[i].sum()\n",
    "    p_ham = (n_word_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    ham_dict[i] = p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for i in message:\n",
    "        if i in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[i]\n",
    "        if i in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[i]\n",
    "    \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.6110907812164506e-32\n",
      "P(Ham|message): 1.0939296794700009e-29\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 0.0\n",
      "P(Ham|message): 0.0\n",
      "Equal probabilities, have a human classify this!\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 4.948779602699111e-13\n",
      "P(Ham|message): 2.910375940524245e-14\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('tease regret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for i in message:\n",
    "        if i in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[i]\n",
    "        if i in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[i]\n",
    "        \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-84-8ab5f3056a83>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['predicted'] = test['sms'].apply(classify_test_set)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>sms</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                sms  \\\n",
       "2131   ham          Later i guess. I needa do mcat study too.   \n",
       "3418   ham             But i haf enuff space got like 4 mb...   \n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...   \n",
       "1538   ham  All sounds good. Fingers . Makes it difficult ...   \n",
       "5393   ham  All done, all handed in. Don't know if mega sh...   \n",
       "\n",
       "                       predicted  \n",
       "2131  needs human classification  \n",
       "3418                         ham  \n",
       "3424  needs human classification  \n",
       "1538                         ham  \n",
       "5393  needs human classification  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['sms'].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47127468581687615\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the spam filter is 47%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
